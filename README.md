# Вопрос-ответ

&nbsp;&nbsp;&nbsp;&nbsp;[Ссылка на ТГ бота](https://t.me/QA_w_context_bot)

&nbsp;&nbsp;&nbsp;&nbsp;[Ссылка на статью](https://huggingface.co/docs/transformers/tasks/question_answering)

&nbsp;&nbsp;&nbsp;&nbsp;Задачи с ответами на вопросы (Question Answering, QA) направлены на автоматическое предоставление ответов на заданные вопросы. Например, если вы когда-либо спрашивали у виртуального помощника, такого как Alexa, Siri или Google, какая сейчас погода, значит, вы уже взаимодействовали с моделью ответа на вопрос.

Существует два основных типа задач QA:

- Экстрактивные (Extractive): Ответ извлекается непосредственно из предоставленного контекста.

- Абстрактные (Abstractive): Ответ генерируется на основе контекста, но может включать в себя новые слова и фразы, не встречающиеся в исходном тексте.

## Реализация QA системы

&nbsp;&nbsp;&nbsp;&nbsp;В реализации своей системы ответов на вопросы (Question Answering, QA) я буду использовать подход, основанный на поиске начального (start) и конечного (end) токенов ответа в тексте вопроса. Этот метод, известный как **экстрактивный QA**, предполагает, что ответ на вопрос содержится в предоставленном контексте и может быть извлечен путем определения соответствующих токенов.

## Модель

&nbsp;&nbsp;&nbsp;&nbsp;Для реализации я выбрал модель **"xlm-roberta-base"**, которая является многоязычной версией модели RoBERTa. Эта модель была предварительно обучена на большом объеме текстовых данных и адаптирована для задачи QA.

&nbsp;&nbsp;&nbsp;&nbsp;В обучении я буду использовать датасет **SberQuAD**, который является русскоязычным аналогом известной английской базы данных **SQuAD** (Stanford Question Answering Dataset). **SberQuAD** содержит пары "вопрос-ответ", основанные на текстовых контекстах, что делает его идеальным выбором для обучения.

    Более подробное описание решения находится в 'Question_Answering.ipynb'
